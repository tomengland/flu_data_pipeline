{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe325bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Connected to database\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine('postgresql://fluuser:flupass@postgres/flu_database')\n",
    "\n",
    "print(\" Connected to database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa29ce12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COLLECTING WA DOH RHINO DATA\n",
      "============================================================\n",
      "\n",
      "‚úì DOH RHINO data loaded: 7896 records\n",
      "  Original columns: ['Season', 'Week Start', 'Week End', 'Week', 'Location', 'Respiratory Illness Category', 'Demographic Category', 'Demographic', 'Care Type', '1-Week Percent ', 'dtm_updated', 'source']\n",
      "\n",
      " Validating County Mapping:\n",
      "     WARNING: Counties not in any ACH: ['Adams', 'Asotin', 'Benton', 'Columbia', 'Franklin', 'Garfield', 'Lincoln', 'Pierce', 'Walla Walla', 'Whitman']\n",
      "      (10 counties: likely Pierce, Adams, Asotin, Benton, Columbia, Franklin, Garfield, Lincoln, Walla Walla, Whitman)\n",
      "   ‚úì 29 counties mapped across 9 ACH regions\n",
      "\n",
      "üóëÔ∏è  Removed 2064 Statewide/Unassigned records\n",
      "   Remaining: 5832 ACH region records\n",
      "\n",
      " After County Explosion:\n",
      "   - Original ACH records: 5832\n",
      "   - Exploded county records: 19440\n",
      "   - Expansion factor: 3.33x\n",
      "\n",
      "   Unique counties in data: 29\n",
      "   Counties: ['Chelan', 'Clallam', 'Clark', 'Cowlitz', 'Douglas', 'Ferry', 'Grant', 'Grays Harbor', 'Island', 'Jefferson', 'King', 'Kitsap', 'Kittitas', 'Klickitat', 'Lewis', 'Mason', 'Okanogan', 'Pacific', 'Pend Oreille', 'San Juan', 'Skagit', 'Skamania', 'Snohomish', 'Spokane', 'Stevens', 'Thurston', 'Wahkiakum', 'Whatcom', 'Yakima']\n",
      "\n",
      " Records per County:\n",
      "   - Chelan: 648 records (ACH: Thriving Together NCW)\n",
      "   - Clallam: 648 records (ACH: Olympic Community of Health)\n",
      "   - Clark: 648 records (ACH: Southwest Washington)\n",
      "   - Cowlitz: 648 records (ACH: Southwest Washington)\n",
      "   - Douglas: 648 records (ACH: Thriving Together NCW)\n",
      "   - Ferry: 648 records (ACH: Better Health Together)\n",
      "   - Grant: 648 records (ACH: Thriving Together NCW)\n",
      "   - Grays Harbor: 648 records (ACH: Cascade Pacific Action Alliance)\n",
      "   - Island: 648 records (ACH: North Sound)\n",
      "   - Jefferson: 648 records (ACH: Olympic Community of Health)\n",
      "   - King: 648 records (ACH: Healthier Here)\n",
      "   - Kitsap: 648 records (ACH: Olympic Community of Health)\n",
      "   - Kittitas: 648 records (ACH: Elevate Health)\n",
      "   - Klickitat: 648 records (ACH: Southwest Washington)\n",
      "   - Lewis: 648 records (ACH: Cascade Pacific Action Alliance)\n",
      "   - Mason: 648 records (ACH: Cascade Pacific Action Alliance)\n",
      "   - Okanogan: 648 records (ACH: Thriving Together NCW)\n",
      "   - Pacific: 648 records (ACH: Cascade Pacific Action Alliance)\n",
      "   - Pend Oreille: 648 records (ACH: Better Health Together)\n",
      "   - San Juan: 648 records (ACH: North Sound)\n",
      "   - Skagit: 648 records (ACH: North Sound)\n",
      "   - Skamania: 648 records (ACH: Southwest Washington)\n",
      "   - Snohomish: 648 records (ACH: North Sound)\n",
      "   - Spokane: 1,296 records (ACH: Better Health Together, Greater Health Now)\n",
      "   - Stevens: 648 records (ACH: Better Health Together)\n",
      "   - Thurston: 648 records (ACH: Cascade Pacific Action Alliance)\n",
      "   - Wahkiakum: 648 records (ACH: Southwest Washington)\n",
      "   - Whatcom: 648 records (ACH: North Sound)\n",
      "   - Yakima: 648 records (ACH: Elevate Health)\n",
      "\n",
      " Date Range:\n",
      "   - From: 2023-10-01\n",
      "   - To: 2025-10-25\n",
      "\n",
      " Data Dimensions:\n",
      "   - Seasons: 3\n",
      "   - Counties: 29\n",
      "   - Respiratory Illnesses: COVID-19, Flu, RSV\n",
      "   - Care Types: Hospitalizations, Emergency Visits\n",
      "   - Demographic Categories: Overall\n",
      "\n",
      " Latest Flu Hospitalizations by County (2025-10-25):\n",
      "   - Jefferson: 0.6% (from Olympic Community of Health)\n",
      "   - Kitsap: 0.6% (from Olympic Community of Health)\n",
      "   - Clallam: 0.6% (from Olympic Community of Health)\n",
      "   - Pacific: 0.2% (from Cascade Pacific Action Alliance)\n",
      "   - Stevens: 0.2% (from Better Health Together)\n",
      "   - King: 0.2% (from Healthier Here)\n",
      "   - Lewis: 0.2% (from Cascade Pacific Action Alliance)\n",
      "   - Spokane: 0.2% (from Better Health Together)\n",
      "   - Grays Harbor: 0.2% (from Cascade Pacific Action Alliance)\n",
      "   - Mason: 0.2% (from Cascade Pacific Action Alliance)\n",
      "\n",
      " Data Quality:\n",
      "   - Total records: 19,440\n",
      "   - Records with data: 19,440 (100.0%)\n",
      "   - Empty/suppressed: 0 (0.0%)\n",
      " Error: Cannot save file into a non-existent directory: '/app/data/raw'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3348/4009952149.py\", line 154, in <module>\n",
      "    df_doh_rhino_exploded.to_csv(output_path, index=False)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/generic.py\", line 3902, in to_csv\n",
      "    return DataFrameRenderer(formatter).to_csv(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/formats/format.py\", line 1152, in to_csv\n",
      "    csv_formatter.save()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/formats/csvs.py\", line 247, in save\n",
      "    with get_handle(\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/common.py\", line 739, in get_handle\n",
      "    check_parent_directory(str(handle))\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/common.py\", line 604, in check_parent_directory\n",
      "    raise OSError(rf\"Cannot save file into a non-existent directory: '{parent}'\")\n",
      "OSError: Cannot save file into a non-existent directory: '/app/data/raw'\n"
     ]
    }
   ],
   "source": [
    "# WA DOH RHINO Data\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COLLECTING WA DOH RHINO DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# WA DOH RHINO downloadable data\n",
    "doh_rhino_url = \"https://doh.wa.gov/sites/default/files/Data/Auto-Uploads/Respiratory-Illness/Respiratory_Disease_RHINO_Downloadable_Data.csv\"\n",
    "\n",
    "# ACH to Counties mapping - MUST match official WA county names exactly\n",
    "ach_to_counties = {\n",
    "    \"Better Health Together\": [\"Spokane\", \"Stevens\", \"Pend Oreille\", \"Ferry\"],\n",
    "    \"Cascade Pacific Action Alliance\": [\"Thurston\", \"Mason\", \"Grays Harbor\", \"Pacific\", \"Lewis\"],\n",
    "    \"Elevate Health\": [\"Yakima\", \"Kittitas\"],\n",
    "    \"Greater Health Now\": [\"Spokane\"],  # Urban Spokane focus - duplicate with Better Health Together\n",
    "    \"Healthier Here\": [\"King\"],\n",
    "    \"North Sound\": [\"Whatcom\", \"Skagit\", \"Snohomish\", \"San Juan\", \"Island\"],\n",
    "    \"Olympic Community of Health\": [\"Clallam\", \"Jefferson\", \"Kitsap\"],\n",
    "    \"Southwest Washington\": [\"Clark\", \"Skamania\", \"Klickitat\", \"Cowlitz\", \"Wahkiakum\"],\n",
    "    \"Thriving Together NCW\": [\"Chelan\", \"Douglas\", \"Grant\", \"Okanogan\"]\n",
    "}\n",
    "\n",
    "# Official WA State counties for validation\n",
    "wa_counties = [\n",
    "    \"Adams\", \"Asotin\", \"Benton\", \"Chelan\", \"Clallam\", \"Clark\", \"Columbia\", \"Cowlitz\",\n",
    "    \"Douglas\", \"Ferry\", \"Franklin\", \"Garfield\", \"Grant\", \"Grays Harbor\", \"Island\",\n",
    "    \"Jefferson\", \"King\", \"Kitsap\", \"Kittitas\", \"Klickitat\", \"Lewis\", \"Lincoln\",\n",
    "    \"Mason\", \"Okanogan\", \"Pacific\", \"Pend Oreille\", \"Pierce\", \"San Juan\", \"Skagit\",\n",
    "    \"Skamania\", \"Snohomish\", \"Spokane\", \"Stevens\", \"Thurston\", \"Wahkiakum\",\n",
    "    \"Walla Walla\", \"Whatcom\", \"Whitman\", \"Yakima\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    df_doh_rhino = pd.read_csv(doh_rhino_url)\n",
    "\n",
    "    # Add source column\n",
    "    df_doh_rhino['source'] = 'WA_DOH_RHINO'\n",
    "\n",
    "    print(f\"\\n‚úì DOH RHINO data loaded: {len(df_doh_rhino)} records\")\n",
    "    print(f\"  Original columns: {df_doh_rhino.columns.tolist()}\")\n",
    "\n",
    "    # Validate counties in mapping\n",
    "    print(f\"\\n Validating County Mapping:\")\n",
    "    all_mapped_counties = set()\n",
    "    for ach, counties in ach_to_counties.items():\n",
    "        all_mapped_counties.update(counties)\n",
    "\n",
    "    # Check for invalid county names\n",
    "    invalid_counties = all_mapped_counties - set(wa_counties)\n",
    "    if invalid_counties:\n",
    "        print(f\"     WARNING: Invalid county names found: {invalid_counties}\")\n",
    "\n",
    "    # Check for unmapped counties\n",
    "    unmapped_counties = set(wa_counties) - all_mapped_counties\n",
    "    if unmapped_counties:\n",
    "        print(f\"     WARNING: Counties not in any ACH: {sorted(unmapped_counties)}\")\n",
    "        print(f\"      ({len(unmapped_counties)} counties: likely Pierce, Adams, Asotin, Benton, Columbia, Franklin, Garfield, Lincoln, Walla Walla, Whitman)\")\n",
    "\n",
    "    print(f\"   ‚úì {len(all_mapped_counties)} counties mapped across {len(ach_to_counties)} ACH regions\")\n",
    "\n",
    "    # Remove Statewide and Unassigned records before exploding\n",
    "    original_count = len(df_doh_rhino)\n",
    "    df_doh_rhino = df_doh_rhino[\n",
    "        ~df_doh_rhino['Location'].isin(['Statewide', 'Unassigned ACH Region'])\n",
    "    ].copy()\n",
    "    removed_count = original_count - len(df_doh_rhino)\n",
    "    print(f\"\\nüóëÔ∏è  Removed {removed_count} Statewide/Unassigned records\")\n",
    "    print(f\"   Remaining: {len(df_doh_rhino)} ACH region records\")\n",
    "\n",
    "    # Map ACH to counties and explode\n",
    "    df_doh_rhino['county_list'] = df_doh_rhino['Location'].map(ach_to_counties)\n",
    "\n",
    "    # Explode: create one row per county\n",
    "    df_doh_rhino_exploded = df_doh_rhino.explode('county_list').reset_index(drop=True)\n",
    "\n",
    "    # Rename county_list to county for clarity\n",
    "    df_doh_rhino_exploded.rename(columns={'county_list': 'county'}, inplace=True)\n",
    "\n",
    "    print(f\"\\n After County Explosion:\")\n",
    "    print(f\"   - Original ACH records: {len(df_doh_rhino)}\")\n",
    "    print(f\"   - Exploded county records: {len(df_doh_rhino_exploded)}\")\n",
    "    print(f\"   - Expansion factor: {len(df_doh_rhino_exploded) / len(df_doh_rhino):.2f}x\")\n",
    "\n",
    "    # Verify unique counties\n",
    "    unique_counties = df_doh_rhino_exploded['county'].unique()\n",
    "    print(f\"\\n   Unique counties in data: {len(unique_counties)}\")\n",
    "    print(f\"   Counties: {sorted(unique_counties)}\")\n",
    "\n",
    "    # Show county record counts\n",
    "    print(f\"\\n Records per County:\")\n",
    "    county_counts = df_doh_rhino_exploded['county'].value_counts().sort_index()\n",
    "    for county, count in county_counts.items():\n",
    "        # Show which ACH regions include this county\n",
    "        achs = [ach for ach, counties in ach_to_counties.items() if county in counties]\n",
    "        ach_str = \", \".join(achs)\n",
    "        print(f\"   - {county}: {count:,} records (ACH: {ach_str})\")\n",
    "\n",
    "    # Date range\n",
    "    print(f\"\\n Date Range:\")\n",
    "    print(f\"   - From: {df_doh_rhino_exploded['Week Start'].min()}\")\n",
    "    print(f\"   - To: {df_doh_rhino_exploded['Week End'].max()}\")\n",
    "\n",
    "    # Clean up the percentage data\n",
    "    def clean_percentage(value):\n",
    "        \"\"\"Convert empty strings to NaN, keep numeric values\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return None\n",
    "        if isinstance(value, str):\n",
    "            if value.strip() == '':\n",
    "                return None\n",
    "        try:\n",
    "            return float(value)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df_doh_rhino_exploded['1-Week Percent_cleaned'] = df_doh_rhino_exploded['1-Week Percent '].apply(clean_percentage)\n",
    "\n",
    "    # Show data dimensions\n",
    "    print(f\"\\n Data Dimensions:\")\n",
    "    print(f\"   - Seasons: {df_doh_rhino_exploded['Season'].nunique()}\")\n",
    "    print(f\"   - Counties: {df_doh_rhino_exploded['county'].nunique()}\")\n",
    "    print(f\"   - Respiratory Illnesses: {', '.join(df_doh_rhino_exploded['Respiratory Illness Category'].unique())}\")\n",
    "    print(f\"   - Care Types: {', '.join(df_doh_rhino_exploded['Care Type'].unique())}\")\n",
    "    print(f\"   - Demographic Categories: {', '.join(df_doh_rhino_exploded['Demographic Category'].unique())}\")\n",
    "\n",
    "    # Example: Latest flu data by county\n",
    "    latest_week = df_doh_rhino_exploded['Week End'].max()\n",
    "    latest_flu_hosp = df_doh_rhino_exploded[\n",
    "        (df_doh_rhino_exploded['Week End'] == latest_week) &\n",
    "        (df_doh_rhino_exploded['Respiratory Illness Category'] == 'Flu') &\n",
    "        (df_doh_rhino_exploded['Care Type'] == 'Hospitalizations') &\n",
    "        (df_doh_rhino_exploded['Demographic Category'] == 'Overall')\n",
    "    ].copy()\n",
    "\n",
    "    if len(latest_flu_hosp) > 0:\n",
    "        print(f\"\\n Latest Flu Hospitalizations by County ({latest_week}):\")\n",
    "        latest_flu_hosp_sorted = latest_flu_hosp.sort_values('1-Week Percent_cleaned', ascending=False)\n",
    "        for _, row in latest_flu_hosp_sorted.head(10).iterrows():\n",
    "            pct = row['1-Week Percent_cleaned']\n",
    "            if pd.notna(pct):\n",
    "                print(f\"   - {row['county']}: {pct}% (from {row['Location']})\")\n",
    "\n",
    "    # Data quality\n",
    "    total_rows = len(df_doh_rhino_exploded)\n",
    "    data_rows = df_doh_rhino_exploded['1-Week Percent_cleaned'].notna().sum()\n",
    "    empty_rows = total_rows - data_rows\n",
    "\n",
    "    print(f\"\\n Data Quality:\")\n",
    "    print(f\"   - Total records: {total_rows:,}\")\n",
    "    print(f\"   - Records with data: {data_rows:,} ({data_rows/total_rows*100:.1f}%)\")\n",
    "    print(f\"   - Empty/suppressed: {empty_rows:,} ({empty_rows/total_rows*100:.1f}%)\")\n",
    "\n",
    "    # Save\n",
    "    output_path = '/app/data/raw/wa_doh_rhino.csv'\n",
    "    df_doh_rhino_exploded.to_csv(output_path, index=False)\n",
    "    print(f\"\\n Saved to: {output_path}\")\n",
    "\n",
    "    print(\"\\nüìã Sample records (showing county-level data):\")\n",
    "    sample_cols = ['county', 'Location', 'Week Start', 'Week End', 'Respiratory Illness Category', 'Care Type', '1-Week Percent_cleaned']\n",
    "    print(df_doh_rhino_exploded[sample_cols].head(20).to_string(index=False))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be649592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COLLECTING CENSUS DATA\n",
      "============================================================\n",
      "\n",
      " Census data loaded: 39 counties\n",
      " Columns: ['County Name', 'Population Density 1900', 'Population Density 1910', 'Population Density 1920', 'Population Density 1930', 'Population Density 1940', 'Population Density 1950', 'Population Density 1960', 'Population Density 1970', 'Population Density 1980', 'Population Density 1990', 'Population Density 2000', 'Population Density 2010', 'Population Density 2020']\n",
      "\n",
      " Missing 2020 density values: 0\n",
      "\n",
      " 2020 Population Density Statistics:\n",
      "count      39.000000\n",
      "mean      149.612821\n",
      "std       250.371017\n",
      "min         3.220000\n",
      "25%        17.550000\n",
      "50%        36.990000\n",
      "75%       104.950000\n",
      "max      1073.020000\n",
      "Name: Population Density 2020, dtype: float64\n",
      "\n",
      " Top 5 Most Dense Counties (2020):\n",
      "County Name  Population Density 2020\n",
      "       King                  1073.02\n",
      "      Clark                   800.82\n",
      "     Kitsap                   697.57\n",
      "     Pierce                   551.81\n",
      "     Island                   416.63\n",
      " Error: Cannot save file into a non-existent directory: '/app/data/raw'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3348/807216807.py\", line 30, in <module>\n",
      "    df_census.to_csv(output_path, index=False)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/generic.py\", line 3902, in to_csv\n",
      "    return DataFrameRenderer(formatter).to_csv(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/formats/format.py\", line 1152, in to_csv\n",
      "    csv_formatter.save()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/formats/csvs.py\", line 247, in save\n",
      "    with get_handle(\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/common.py\", line 739, in get_handle\n",
      "    check_parent_directory(str(handle))\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/common.py\", line 604, in check_parent_directory\n",
      "    raise OSError(rf\"Cannot save file into a non-existent directory: '{parent}'\")\n",
      "OSError: Cannot save file into a non-existent directory: '/app/data/raw'\n"
     ]
    }
   ],
   "source": [
    "## Collect census\n",
    "print(\"=\" * 60)\n",
    "print(\"COLLECTING CENSUS DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Download census data\n",
    "census_url = \"https://data.wa.gov/api/views/e6ip-wkqq/rows.csv?accessType=DOWNLOAD\"\n",
    "\n",
    "try:\n",
    "    df_census = pd.read_csv(census_url)\n",
    "\n",
    "    print(f\"\\n Census data loaded: {len(df_census)} counties\")\n",
    "    print(f\" Columns: {df_census.columns.tolist()}\")\n",
    "\n",
    "    # Check for missing values in 2020 data\n",
    "    missing_2020 = df_census['Population Density 2020'].isna().sum()\n",
    "    print(f\"\\n Missing 2020 density values: {missing_2020}\")\n",
    "\n",
    "    # Show summary statistics\n",
    "    print(\"\\n 2020 Population Density Statistics:\")\n",
    "    print(df_census['Population Density 2020'].describe())\n",
    "\n",
    "    # Show top 5 most dense counties\n",
    "    print(\"\\n Top 5 Most Dense Counties (2020):\")\n",
    "    top_counties = df_census.nlargest(5, 'Population Density 2020')[['County Name', 'Population Density 2020']]\n",
    "    print(top_counties.to_string(index=False))\n",
    "\n",
    "    # Save to raw data\n",
    "    output_path = '/app/data/raw/wa_population_density.csv'\n",
    "    df_census.to_csv(output_path, index=False)\n",
    "    print(f\"\\n Saved to: {output_path}\")\n",
    "\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df_census.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c580ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COLLECTING CDC FLUVIEW DATA\n",
      "============================================================\n",
      "\n",
      " FluView data loaded: 261 weeks\n",
      " Date range: 202001 to 202452\n",
      "\n",
      " Key columns:\n",
      "   ['region', 'epiweek', 'num_ili', 'num_patients', 'wili']\n",
      "\n",
      " ILI Statistics:\n",
      "   - Average ILI cases per week: 772\n",
      "   - Max ILI cases in a week: 6043\n",
      "   - Average % ILI: 1.72%\n",
      "   - Max % ILI: 12.93%\n",
      "\n",
      " Top 5 Weeks by ILI Percentage:\n",
      " epiweek  num_ili  num_patients     wili\n",
      "  202247     5945         45967 12.93320\n",
      "  202248     6043         51505 11.73280\n",
      "  202249     5284         49549 10.66420\n",
      "  202250     4365         48328  9.03203\n",
      "  202246     3563         47539  7.49490\n",
      " Error: Cannot save file into a non-existent directory: '/app/data/raw'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3348/4098532632.py\", line 48, in <module>\n",
      "    df_fluview.to_csv(output_path, index=False)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/core/generic.py\", line 3902, in to_csv\n",
      "    return DataFrameRenderer(formatter).to_csv(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/formats/format.py\", line 1152, in to_csv\n",
      "    csv_formatter.save()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/formats/csvs.py\", line 247, in save\n",
      "    with get_handle(\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/common.py\", line 739, in get_handle\n",
      "    check_parent_directory(str(handle))\n",
      "  File \"/usr/local/lib/python3.11/site-packages/pandas/io/common.py\", line 604, in check_parent_directory\n",
      "    raise OSError(rf\"Cannot save file into a non-existent directory: '{parent}'\")\n",
      "OSError: Cannot save file into a non-existent directory: '/app/data/raw'\n"
     ]
    }
   ],
   "source": [
    "##CDC Flu\n",
    "\n",
    "import requests\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COLLECTING CDC FLUVIEW DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# API endpoint\n",
    "api_url = \"https://api.delphi.cmu.edu/epidata/fluview/\"\n",
    "\n",
    "# Parameters - Get data from 2020 onwards\n",
    "params = {\n",
    "    'regions': 'wa',\n",
    "    'epiweeks': '202001-202452'  # 2020 through 2024\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Make API request\n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if successful\n",
    "    if data['result'] == 1:\n",
    "        df_fluview = pd.DataFrame(data['epidata'])\n",
    "\n",
    "        print(f\"\\n FluView data loaded: {len(df_fluview)} weeks\")\n",
    "        print(f\" Date range: {df_fluview['epiweek'].min()} to {df_fluview['epiweek'].max()}\")\n",
    "\n",
    "        # Show key columns\n",
    "        print(f\"\\n Key columns:\")\n",
    "        key_cols = ['region', 'epiweek', 'num_ili', 'num_patients', 'wili']\n",
    "        print(f\"   {key_cols}\")\n",
    "\n",
    "        # Summary statistics\n",
    "        print(\"\\n ILI Statistics:\")\n",
    "        print(f\"   - Average ILI cases per week: {df_fluview['num_ili'].mean():.0f}\")\n",
    "        print(f\"   - Max ILI cases in a week: {df_fluview['num_ili'].max()}\")\n",
    "        print(f\"   - Average % ILI: {df_fluview['wili'].mean():.2f}%\")\n",
    "        print(f\"   - Max % ILI: {df_fluview['wili'].max():.2f}%\")\n",
    "\n",
    "        # Show weeks with highest ILI\n",
    "        print(\"\\n Top 5 Weeks by ILI Percentage:\")\n",
    "        top_ili = df_fluview.nlargest(5, 'wili')[['epiweek', 'num_ili', 'num_patients', 'wili']]\n",
    "        print(top_ili.to_string(index=False))\n",
    "\n",
    "        # Save to raw data\n",
    "        output_path = '/app/data/raw/wa_fluview_data.csv'\n",
    "        df_fluview.to_csv(output_path, index=False)\n",
    "        print(f\"\\n Saved to: {output_path}\")\n",
    "\n",
    "        print(\"\\nFirst 5 rows:\")\n",
    "        print(df_fluview.head())\n",
    "\n",
    "    else:\n",
    "        print(f\" API Error: {data.get('message', 'Unknown error')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9807e3f",
   "metadata": {},
   "source": [
    " ## Clean Data and Create Additional Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287459f1",
   "metadata": {},
   "source": [
    "### Check Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6efe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>region</th>\n",
       "      <th>issue</th>\n",
       "      <th>epiweek</th>\n",
       "      <th>lag</th>\n",
       "      <th>num_ili</th>\n",
       "      <th>num_patients</th>\n",
       "      <th>num_providers</th>\n",
       "      <th>num_age_0</th>\n",
       "      <th>num_age_1</th>\n",
       "      <th>num_age_2</th>\n",
       "      <th>num_age_3</th>\n",
       "      <th>num_age_4</th>\n",
       "      <th>num_age_5</th>\n",
       "      <th>wili</th>\n",
       "      <th>ili</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>wa</td>\n",
       "      <td>202139</td>\n",
       "      <td>202001</td>\n",
       "      <td>91</td>\n",
       "      <td>1449</td>\n",
       "      <td>20298</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7.13863</td>\n",
       "      <td>7.13863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>wa</td>\n",
       "      <td>202139</td>\n",
       "      <td>202002</td>\n",
       "      <td>90</td>\n",
       "      <td>1075</td>\n",
       "      <td>22028</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.88015</td>\n",
       "      <td>4.88015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>wa</td>\n",
       "      <td>202139</td>\n",
       "      <td>202003</td>\n",
       "      <td>89</td>\n",
       "      <td>853</td>\n",
       "      <td>20215</td>\n",
       "      <td>54</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.21964</td>\n",
       "      <td>4.21964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>wa</td>\n",
       "      <td>202139</td>\n",
       "      <td>202004</td>\n",
       "      <td>88</td>\n",
       "      <td>966</td>\n",
       "      <td>21871</td>\n",
       "      <td>54</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.41681</td>\n",
       "      <td>4.41681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>wa</td>\n",
       "      <td>202139</td>\n",
       "      <td>202005</td>\n",
       "      <td>87</td>\n",
       "      <td>1044</td>\n",
       "      <td>22260</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.69003</td>\n",
       "      <td>4.69003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  release_date region   issue  epiweek  lag  num_ili  num_patients  \\\n",
       "0   2021-10-08     wa  202139   202001   91     1449         20298   \n",
       "1   2021-10-08     wa  202139   202002   90     1075         22028   \n",
       "2   2021-10-08     wa  202139   202003   89      853         20215   \n",
       "3   2021-10-08     wa  202139   202004   88      966         21871   \n",
       "4   2021-10-08     wa  202139   202005   87     1044         22260   \n",
       "\n",
       "   num_providers num_age_0 num_age_1 num_age_2 num_age_3 num_age_4 num_age_5  \\\n",
       "0             55      None      None      None      None      None      None   \n",
       "1             55      None      None      None      None      None      None   \n",
       "2             54      None      None      None      None      None      None   \n",
       "3             54      None      None      None      None      None      None   \n",
       "4             55      None      None      None      None      None      None   \n",
       "\n",
       "      wili      ili  \n",
       "0  7.13863  7.13863  \n",
       "1  4.88015  4.88015  \n",
       "2  4.21964  4.21964  \n",
       "3  4.41681  4.41681  \n",
       "4  4.69003  4.69003  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FluView\n",
    "df_fluview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f1b46b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Week Start</th>\n",
       "      <th>Week End</th>\n",
       "      <th>Week</th>\n",
       "      <th>Location</th>\n",
       "      <th>Respiratory Illness Category</th>\n",
       "      <th>Demographic Category</th>\n",
       "      <th>Demographic</th>\n",
       "      <th>Care Type</th>\n",
       "      <th>1-Week Percent</th>\n",
       "      <th>dtm_updated</th>\n",
       "      <th>source</th>\n",
       "      <th>county</th>\n",
       "      <th>1-Week Percent_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>Better Health Together</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>All</td>\n",
       "      <td>Hospitalizations</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2025-10-28 15:15:32.795801</td>\n",
       "      <td>WA_DOH_RHINO</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>Better Health Together</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>All</td>\n",
       "      <td>Hospitalizations</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2025-10-28 15:15:32.795801</td>\n",
       "      <td>WA_DOH_RHINO</td>\n",
       "      <td>Stevens</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>Better Health Together</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>All</td>\n",
       "      <td>Hospitalizations</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2025-10-28 15:15:32.795801</td>\n",
       "      <td>WA_DOH_RHINO</td>\n",
       "      <td>Pend Oreille</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>Better Health Together</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>All</td>\n",
       "      <td>Hospitalizations</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2025-10-28 15:15:32.795801</td>\n",
       "      <td>WA_DOH_RHINO</td>\n",
       "      <td>Ferry</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>Better Health Together</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>All</td>\n",
       "      <td>Emergency Visits</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2025-10-28 15:15:32.795801</td>\n",
       "      <td>WA_DOH_RHINO</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  Week Start    Week End  Week                Location  \\\n",
       "0  2023-2024  2023-10-01  2023-10-07    40  Better Health Together   \n",
       "1  2023-2024  2023-10-01  2023-10-07    40  Better Health Together   \n",
       "2  2023-2024  2023-10-01  2023-10-07    40  Better Health Together   \n",
       "3  2023-2024  2023-10-01  2023-10-07    40  Better Health Together   \n",
       "4  2023-2024  2023-10-01  2023-10-07    40  Better Health Together   \n",
       "\n",
       "  Respiratory Illness Category Demographic Category Demographic  \\\n",
       "0                     COVID-19              Overall         All   \n",
       "1                     COVID-19              Overall         All   \n",
       "2                     COVID-19              Overall         All   \n",
       "3                     COVID-19              Overall         All   \n",
       "4                     COVID-19              Overall         All   \n",
       "\n",
       "          Care Type  1-Week Percent                  dtm_updated  \\\n",
       "0  Hospitalizations              3.8  2025-10-28 15:15:32.795801   \n",
       "1  Hospitalizations              3.8  2025-10-28 15:15:32.795801   \n",
       "2  Hospitalizations              3.8  2025-10-28 15:15:32.795801   \n",
       "3  Hospitalizations              3.8  2025-10-28 15:15:32.795801   \n",
       "4  Emergency Visits              2.7  2025-10-28 15:15:32.795801   \n",
       "\n",
       "         source        county  1-Week Percent_cleaned  \n",
       "0  WA_DOH_RHINO       Spokane                     3.8  \n",
       "1  WA_DOH_RHINO       Stevens                     3.8  \n",
       "2  WA_DOH_RHINO  Pend Oreille                     3.8  \n",
       "3  WA_DOH_RHINO         Ferry                     3.8  \n",
       "4  WA_DOH_RHINO       Spokane                     2.7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rhino Exploded\n",
    "df_doh_rhino_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fba3c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Week Start</th>\n",
       "      <th>Week End</th>\n",
       "      <th>Week</th>\n",
       "      <th>Location</th>\n",
       "      <th>Respiratory Illness Category</th>\n",
       "      <th>Demographic Category</th>\n",
       "      <th>Demographic</th>\n",
       "      <th>Care Type</th>\n",
       "      <th>1-Week Percent</th>\n",
       "      <th>dtm_updated</th>\n",
       "      <th>source</th>\n",
       "      <th>county_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>Better Health Together</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>All</td>\n",
       "      <td>Hospitalizations</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2025-10-28 15:15:32.795801</td>\n",
       "      <td>WA_DOH_RHINO</td>\n",
       "      <td>[Spokane, Stevens, Pend Oreille, Ferry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>Better Health Together</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>All</td>\n",
       "      <td>Emergency Visits</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2025-10-28 15:15:32.795801</td>\n",
       "      <td>WA_DOH_RHINO</td>\n",
       "      <td>[Spokane, Stevens, Pend Oreille, Ferry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>Cascade Pacific Action Alliance</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>All</td>\n",
       "      <td>Hospitalizations</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2025-10-28 15:15:32.795801</td>\n",
       "      <td>WA_DOH_RHINO</td>\n",
       "      <td>[Thurston, Mason, Grays Harbor, Pacific, Lewis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>Cascade Pacific Action Alliance</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>All</td>\n",
       "      <td>Emergency Visits</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2025-10-28 15:15:32.795801</td>\n",
       "      <td>WA_DOH_RHINO</td>\n",
       "      <td>[Thurston, Mason, Grays Harbor, Pacific, Lewis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>Elevate Health</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>All</td>\n",
       "      <td>Hospitalizations</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2025-10-28 15:15:32.795801</td>\n",
       "      <td>WA_DOH_RHINO</td>\n",
       "      <td>[Yakima, Kittitas]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  Week Start    Week End  Week                         Location  \\\n",
       "0  2023-2024  2023-10-01  2023-10-07    40           Better Health Together   \n",
       "1  2023-2024  2023-10-01  2023-10-07    40           Better Health Together   \n",
       "2  2023-2024  2023-10-01  2023-10-07    40  Cascade Pacific Action Alliance   \n",
       "3  2023-2024  2023-10-01  2023-10-07    40  Cascade Pacific Action Alliance   \n",
       "4  2023-2024  2023-10-01  2023-10-07    40                   Elevate Health   \n",
       "\n",
       "  Respiratory Illness Category Demographic Category Demographic  \\\n",
       "0                     COVID-19              Overall         All   \n",
       "1                     COVID-19              Overall         All   \n",
       "2                     COVID-19              Overall         All   \n",
       "3                     COVID-19              Overall         All   \n",
       "4                     COVID-19              Overall         All   \n",
       "\n",
       "          Care Type  1-Week Percent                  dtm_updated  \\\n",
       "0  Hospitalizations              3.8  2025-10-28 15:15:32.795801   \n",
       "1  Emergency Visits              2.7  2025-10-28 15:15:32.795801   \n",
       "2  Hospitalizations              3.8  2025-10-28 15:15:32.795801   \n",
       "3  Emergency Visits              2.5  2025-10-28 15:15:32.795801   \n",
       "4  Hospitalizations              2.3  2025-10-28 15:15:32.795801   \n",
       "\n",
       "         source                                      county_list  \n",
       "0  WA_DOH_RHINO          [Spokane, Stevens, Pend Oreille, Ferry]  \n",
       "1  WA_DOH_RHINO          [Spokane, Stevens, Pend Oreille, Ferry]  \n",
       "2  WA_DOH_RHINO  [Thurston, Mason, Grays Harbor, Pacific, Lewis]  \n",
       "3  WA_DOH_RHINO  [Thurston, Mason, Grays Harbor, Pacific, Lewis]  \n",
       "4  WA_DOH_RHINO                               [Yakima, Kittitas]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rhino\n",
    "df_doh_rhino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a39cbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County Name</th>\n",
       "      <th>Population Density 1900</th>\n",
       "      <th>Population Density 1910</th>\n",
       "      <th>Population Density 1920</th>\n",
       "      <th>Population Density 1930</th>\n",
       "      <th>Population Density 1940</th>\n",
       "      <th>Population Density 1950</th>\n",
       "      <th>Population Density 1960</th>\n",
       "      <th>Population Density 1970</th>\n",
       "      <th>Population Density 1980</th>\n",
       "      <th>Population Density 1990</th>\n",
       "      <th>Population Density 2000</th>\n",
       "      <th>Population Density 2010</th>\n",
       "      <th>Population Density 2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adams</td>\n",
       "      <td>2.51</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.01</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.42</td>\n",
       "      <td>5.16</td>\n",
       "      <td>6.24</td>\n",
       "      <td>6.89</td>\n",
       "      <td>7.07</td>\n",
       "      <td>8.53</td>\n",
       "      <td>9.73</td>\n",
       "      <td>10.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asotin</td>\n",
       "      <td>5.29</td>\n",
       "      <td>9.17</td>\n",
       "      <td>10.28</td>\n",
       "      <td>12.79</td>\n",
       "      <td>13.15</td>\n",
       "      <td>17.11</td>\n",
       "      <td>20.30</td>\n",
       "      <td>21.70</td>\n",
       "      <td>26.46</td>\n",
       "      <td>27.69</td>\n",
       "      <td>32.35</td>\n",
       "      <td>33.99</td>\n",
       "      <td>35.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.66</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.43</td>\n",
       "      <td>7.08</td>\n",
       "      <td>30.16</td>\n",
       "      <td>36.45</td>\n",
       "      <td>39.66</td>\n",
       "      <td>64.26</td>\n",
       "      <td>66.09</td>\n",
       "      <td>83.66</td>\n",
       "      <td>103.02</td>\n",
       "      <td>121.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chelan</td>\n",
       "      <td>1.35</td>\n",
       "      <td>5.17</td>\n",
       "      <td>7.16</td>\n",
       "      <td>10.83</td>\n",
       "      <td>11.78</td>\n",
       "      <td>13.45</td>\n",
       "      <td>13.95</td>\n",
       "      <td>14.15</td>\n",
       "      <td>15.42</td>\n",
       "      <td>17.88</td>\n",
       "      <td>22.80</td>\n",
       "      <td>24.81</td>\n",
       "      <td>27.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clallam</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.87</td>\n",
       "      <td>6.51</td>\n",
       "      <td>11.72</td>\n",
       "      <td>12.52</td>\n",
       "      <td>15.12</td>\n",
       "      <td>17.20</td>\n",
       "      <td>19.92</td>\n",
       "      <td>29.59</td>\n",
       "      <td>32.20</td>\n",
       "      <td>36.90</td>\n",
       "      <td>41.08</td>\n",
       "      <td>44.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  County Name  Population Density 1900  Population Density 1910  \\\n",
       "0       Adams                     2.51                     5.67   \n",
       "1      Asotin                     5.29                     9.17   \n",
       "2      Benton                      NaN                     4.66   \n",
       "3      Chelan                     1.35                     5.17   \n",
       "4     Clallam                     3.21                     3.87   \n",
       "\n",
       "   Population Density 1920  Population Density 1930  Population Density 1940  \\\n",
       "0                     5.00                     4.01                     3.23   \n",
       "1                    10.28                    12.79                    13.15   \n",
       "2                     6.40                     6.43                     7.08   \n",
       "3                     7.16                    10.83                    11.78   \n",
       "4                     6.51                    11.72                    12.52   \n",
       "\n",
       "   Population Density 1950  Population Density 1960  Population Density 1970  \\\n",
       "0                     3.42                     5.16                     6.24   \n",
       "1                    17.11                    20.30                    21.70   \n",
       "2                    30.16                    36.45                    39.66   \n",
       "3                    13.45                    13.95                    14.15   \n",
       "4                    15.12                    17.20                    19.92   \n",
       "\n",
       "   Population Density 1980  Population Density 1990  Population Density 2000  \\\n",
       "0                     6.89                     7.07                     8.53   \n",
       "1                    26.46                    27.69                    32.35   \n",
       "2                    64.26                    66.09                    83.66   \n",
       "3                    15.42                    17.88                    22.80   \n",
       "4                    29.59                    32.20                    36.90   \n",
       "\n",
       "   Population Density 2010  Population Density 2020  \n",
       "0                     9.73                    10.71  \n",
       "1                    33.99                    35.04  \n",
       "2                   103.02                   121.68  \n",
       "3                    24.81                    27.09  \n",
       "4                    41.08                    44.37  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Census\n",
    "df_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bee6b1",
   "metadata": {},
   "source": [
    "### Create DataFrames from above to correspond to tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table 1 DF -----------------------------------------------------------------------------------\n",
    "\n",
    "# Set up unique county names\n",
    "df_county_region = df_census[['County Name', 'Population Density 2020']].drop_duplicates().sort_values(by='County Name', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Add ACH region based on county\n",
    "df_county_region = pd.merge(df_county_region, df_doh_rhino_exploded[['county', 'Location']].drop_duplicates(), left_on='County Name', right_on='county', how='left')\n",
    "\n",
    "# Combine Spokane ACH regions\n",
    "df_county_region = (df_county_region.groupby([\"County Name\", \"Population Density 2020\"], dropna=False)[\"Location\"].apply(lambda x: \", \".join(sorted(x.dropna().unique()))).reset_index())\n",
    "df_county_region['Location'].replace(r'^\\s*$', 'Unassigned', regex = True, inplace=True)\n",
    "\n",
    "# Add in county_id \n",
    "df_county_region['county_id'] = df_county_region.index + 1\n",
    "\n",
    "# Rename columns\n",
    "df_county_region.rename(columns={'County Name': 'county_name', 'Location': 'ach_region', 'Population Density 2020': 'population_density_2020'}, inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "df_county_region = df_county_region[['county_id', 'county_name', 'ach_region', 'population_density_2020']]\n",
    "\n",
    "# Create Table 2 DF -------------------------------------------------------------------------------------\n",
    "\n",
    "# Create rhino epiweek_id column\n",
    "df_doh_rhino_exploded['epiweek_id'] = df_doh_rhino_exploded['Week End'].str[:4] + df_doh_rhino_exploded['Week'].astype(str).str.zfill(2)\n",
    "\n",
    "df_temporal = df_doh_rhino_exploded[['epiweek_id', 'Week Start', 'Week End', 'Season']].drop_duplicates().reset_index(drop=True)\n",
    "df_temporal = df_temporal.sort_values(by=['epiweek_id'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Convert Datatypes (Later...)\n",
    "df_temporal['epiweek_id'] = df_temporal['epiweek_id'].astype(int)\n",
    "df_temporal['Week Start'] = pd.to_datetime(df_temporal['Week Start'])\n",
    "df_temporal['Week End'] = pd.to_datetime(df_temporal['Week End'])\n",
    "\n",
    "# Rename Columns\n",
    "df_temporal.rename(columns={'Week Start': 'week_start', 'Week End': 'week_end', 'Season': 'season'}, inplace=True)\n",
    "\n",
    "# Create Table 3 DF ---------------------------------------------------------------------------------------\n",
    "\n",
    "df_illness = df_doh_rhino_exploded[['epiweek_id', 'county', 'Respiratory Illness Category', 'Care Type', '1-Week Percent_cleaned']].copy()\n",
    "\n",
    "# Add in county_id by merging with county_region DF\n",
    "df_illness = pd.merge(df_illness, df_county_region[['county_id', 'county_name']], left_on='county', right_on='county_name', how='left')\n",
    "df_illness.drop(columns=['county', 'county_name'], inplace=True)\n",
    "\n",
    "# Add in state_ili_percent from fluview\n",
    "df_illness['epiweek_id'] = df_illness['epiweek_id'].astype(int)\n",
    "df_illness = pd.merge(df_illness, df_fluview[['epiweek', 'wili']], left_on='epiweek_id', right_on='epiweek', how='left')\n",
    "df_illness.rename(columns={'wili': 'state_ili_percent'}, inplace=True)\n",
    "df_illness.drop(columns=['epiweek'], inplace=True)\n",
    "df_illness.drop_duplicates(subset=['epiweek_id', 'county_id', 'Respiratory Illness Category', 'Care Type'], inplace=True)\n",
    "\n",
    "# Create Difference Column\n",
    "df_illness['deviation_from_state_average'] = df_illness['1-Week Percent_cleaned'] - df_illness['state_ili_percent']\n",
    "\n",
    "# Rename Columns\n",
    "df_illness.rename(columns={'Respiratory Illness Category': 'respiratory_illness_type',\n",
    "                            'Care Type': 'care_type',\n",
    "                            '1-Week Percent_cleaned': 'county_ili_percent'}, inplace=True)\n",
    "\n",
    "# Reorder Columns\n",
    "df_illness = df_illness[['epiweek_id', 'county_id', 'respiratory_illness_type', 'care_type', 'county_ili_percent', 'state_ili_percent', 'deviation_from_state_average']]\n",
    "\n",
    "\n",
    "# Create Table 4 DF-------------------------------------------------------------------------------------\n",
    "\n",
    "df_healthcare = df_county_region[['county_id', 'county_name', 'population_density_2020']].copy()\n",
    "df_healthcare = pd.merge(df_healthcare, df_doh_rhino_exploded[['county', 'Respiratory Illness Category', 'Care Type', '1-Week Percent_cleaned']].drop_duplicates(), left_on='county_name', right_on='county', how='left')\n",
    "\n",
    "# Add in and calculated generics rates\n",
    "df_healthcare['rates'] = df_healthcare.groupby(['county_id', 'Care Type'])['1-Week Percent_cleaned'].transform('mean')\n",
    "\n",
    "# Drop Extra Columns\n",
    "df_healthcare.drop(columns=['county', '1-Week Percent_cleaned', 'county_name', 'Respiratory Illness Category'], inplace=True)\n",
    "\n",
    "# Combine by groups\n",
    "df_healthcare = df_healthcare.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Separate by Care Type\n",
    "df_healthcare['hospitalization_percent'] = df_healthcare.apply(lambda row: row['rates'] if row['Care Type'] == 'Hospitalizations' else None, axis=1)\n",
    "df_healthcare['er_visit_percent'] = df_healthcare.apply(lambda row: row['rates'] if row['Care Type'] == 'Emergency Visits' else None, axis=1)\n",
    "\n",
    "# Consolidate and drop extras\n",
    "df_healthcare.drop(columns=['Care Type', 'rates'], inplace=True)\n",
    "df_healthcare = df_healthcare.groupby(['county_id', 'population_density_2020'], as_index=False).agg('first')\n",
    "\n",
    "# Calculate Ratio\n",
    "df_healthcare['hospital_to_er_ratio'] = df_healthcare['hospitalization_percent'] / df_healthcare['er_visit_percent']\n",
    "\n",
    "# Fill NaN\n",
    "df_healthcare.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Create Table 5 DF-------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Starting Point\n",
    "df_historics = df_fluview[['epiweek','wili']].copy()\n",
    "\n",
    "# Create year and decade_year\n",
    "df_historics['year'] = df_historics['epiweek'].astype(str).str[:4].astype(int)\n",
    "df_historics['decade_year'] = (df_historics['year'] // 10) * 10\n",
    "\n",
    "# Find Peak wili and epiweek id\n",
    "df_historics['peak_ili_percent'] = df_historics.groupby('year')['wili'].transform('max')\n",
    "df_historics['peak_week_id'] = df_historics.groupby('year')['wili'].transform(lambda x: df_historics.loc[x.idxmax(), 'epiweek'])\n",
    "\n",
    "# Find yearly average\n",
    "df_historics['average_wili_percent'] = df_historics.groupby('year')['wili'].transform('mean')\n",
    "\n",
    "# Find peak vs average difference\n",
    "df_historics['peak_vs_avg_diff'] = df_historics['peak_ili_percent'] - df_historics['average_wili_percent']\n",
    "\n",
    "# Skip population density \n",
    "\n",
    "# Reorder columns\n",
    "df_historics = df_historics[['year', 'decade_year', 'peak_week_id', 'peak_ili_percent', 'average_wili_percent', 'peak_vs_avg_diff']].drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e72740d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all DFs for accuracy\n",
    "#df_county_region.head(60)\n",
    "#df_illness.head(60)\n",
    "#df_temporal.head(60)\n",
    "#df_healthcare.head(60)\n",
    "#df_historics.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4188c3c",
   "metadata": {},
   "source": [
    "### Convert all DFs to CSV for SQL Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea37b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()\n",
    "\n",
    "temporal_path = '/app/processed_files/temporal.csv'\n",
    "illness_path = '/app/processed_files/illness.csv'\n",
    "healthcare_path = '/app/processed_files/healthcare.csv'\n",
    "historic_path = '/app/processed_files/historic_flu.csv'\n",
    "county_region_path = '/app/processed_files/county_region.csv'\n",
    "\n",
    "# Export all DFs to CSV for SQL Ingest\n",
    "df_temporal.to_csv('/app/processed_files/temporal.csv', index=False)\n",
    "df_illness.to_csv('/app/processed_files/illness.csv', index=False)\n",
    "df_healthcare.to_csv('/app/processed_files/healthcare.csv', index=False)\n",
    "df_historics.to_csv('/app/processed_files/historic_flu.csv', index=False)\n",
    "df_county_region.to_csv('/app/processed_files/county_region.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2bb70",
   "metadata": {},
   "source": [
    "## Create PostgreSQL Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504b9747",
   "metadata": {},
   "source": [
    "### Open Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "080f9457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Connected to PostgreSQL database\n"
     ]
    }
   ],
   "source": [
    "# Connect to PostgreSQL DB (Using psycopg2)\n",
    "conn = psycopg2.connect(\n",
    "    dbname='flu_database',\n",
    "    user='fluuser',\n",
    "    password='flupass',\n",
    "    host='postgres',\n",
    "    port='5432'\n",
    ")\n",
    "\n",
    "print(\" Connected to PostgreSQL database\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54ab76",
   "metadata": {},
   "source": [
    "### Create Tables and Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1cf985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Table 1 created\n",
      " Table 2 created\n",
      " Table 3 created\n",
      " Table 4 created\n",
      " Table 5 created\n",
      " All Tables created in PostgreSQL database\n"
     ]
    }
   ],
   "source": [
    "# Rollback previous transactions (Good for troubleshooting)\n",
    "#conn.rollback()\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create Schema\n",
    "cur.execute(\"CREATE SCHEMA IF NOT EXISTS flu_schema;\")\n",
    "\n",
    "# Create Table 1 (County/Region Reference)\n",
    "cur.execute(\"DROP TABLE IF EXISTS flu_schema.county_region;\")\n",
    "cur.execute(\"\"\"CREATE TABLE county_region (\n",
    "                county_id INT PRIMARY KEY, \n",
    "                county_name TEXT,\n",
    "                ach_region TEXT,\n",
    "                population_density_202 FLOAT\n",
    "                );\"\"\"\n",
    "            )\n",
    "print(\" Table 1 created\")\n",
    "\n",
    "# Create Table 2 (Temporal Reference)\n",
    "cur.execute(\"DROP TABLE IF EXISTS flu_schema.temporal;\")\n",
    "cur.execute(\"\"\"CREATE TABLE temporal (\n",
    "                epiweek_id INT PRIMARY KEY, \n",
    "                week_start DATE,\n",
    "                week_end DATE,\n",
    "                season TEXT\n",
    "                );\"\"\"\n",
    "            )\n",
    "print(\" Table 2 created\")\n",
    "\n",
    "\n",
    "# Create Table 3 (County/Weekly Illness Comparison)\n",
    "cur.execute(\"DROP TABLE IF EXISTS flu_schema.illness;\")\n",
    "cur.execute(\"\"\"CREATE TABLE illness (\n",
    "                epiweek_id INT,\n",
    "                FOREIGN KEY (epiweek_id) REFERENCES temporal(epiweek_id),\n",
    "                county_id INT,\n",
    "                FOREIGN KEY (county_id) REFERENCES county_region(county_id),\n",
    "                respiratory_illness_type TEXT,\n",
    "                care_type TEXT,\n",
    "                PRIMARY KEY (epiweek_id, county_id, respiratory_illness_type, care_type),\n",
    "                county_ili_percent FLOAT,\n",
    "                state_ili_percent FLOAT, \n",
    "                deviation_from_state_average FLOAT\n",
    "                );\"\"\"\n",
    "            )\n",
    "print(\" Table 3 created\")\n",
    "\n",
    "\n",
    "# Create Table 4 (Healthcare Utilization)\n",
    "cur.execute(\"DROP TABLE IF EXISTS flu_schema.healthcare;\")\n",
    "cur.execute(\"\"\"CREATE TABLE healthcare (\n",
    "                county_id INT PRIMARY KEY,\n",
    "                population_density_2020 FLOAT,\n",
    "                hospitalization_percent FLOAT,\n",
    "                er_visit_percent FLOAT,\n",
    "                hospital_to_er_ratio FLOAT,\n",
    "                FOREIGN KEY (county_id) REFERENCES county_region(county_id)\n",
    "                );\"\"\"\n",
    "            )\n",
    "print(\" Table 4 created\")\n",
    "\n",
    "\n",
    "# Create Table 5 (Historical Flue Season Summary)\n",
    "cur.execute(\"DROP TABLE IF EXISTS flu_schema.historics;\")\n",
    "cur.execute(\"\"\"CREATE TABLE historics (\n",
    "                year INT PRIMARY KEY,\n",
    "                decade_year INT,\n",
    "                peak_week_id INT,\n",
    "                peak_ili_percent FLOAT,\n",
    "                average_wili_percent FLOAT,\n",
    "                peak_vs_avg_diff FLOAT\n",
    "                );\"\"\"\n",
    "            )\n",
    "print(\" Table 5 created\")\n",
    "\n",
    "print(\" All Tables created in PostgreSQL database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f1170",
   "metadata": {},
   "source": [
    "### Add changes from .csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f01cbc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Table 1 data ingested\n",
      " Table 2 data ingested\n",
      " Table 3 data ingested\n",
      " Table 4 data ingested\n",
      " Table 5 data ingested\n"
     ]
    }
   ],
   "source": [
    "#Rollback \n",
    "#conn.rollback()\n",
    "\n",
    "# Country Region Ingest\n",
    "with open(county_region_path, 'r') as f:\n",
    "    sql = \"\"\"\n",
    "        COPY county_region\n",
    "        FROM STDIN\n",
    "        WITH (FORMAT CSV, HEADER TRUE)\n",
    "    \"\"\"\n",
    "    cur.copy_expert(sql, f)\n",
    "\n",
    "print(\" Table 1 data ingested\")\n",
    "\n",
    "# Temporal Ingest\n",
    "with open(temporal_path, 'r') as f:\n",
    "    sql = \"\"\"\n",
    "        COPY temporal\n",
    "        FROM STDIN\n",
    "        WITH (FORMAT CSV, HEADER TRUE)\n",
    "    \"\"\"\n",
    "    cur.copy_expert(sql, f)\n",
    "\n",
    "print(\" Table 2 data ingested\")\n",
    "\n",
    "# Illness Ingest\n",
    "with open(illness_path, 'r') as f:\n",
    "    sql = \"\"\"\n",
    "        COPY illness\n",
    "        FROM STDIN\n",
    "        WITH (FORMAT CSV, HEADER TRUE)\n",
    "    \"\"\"\n",
    "    cur.copy_expert(sql, f)\n",
    "\n",
    "print(\" Table 3 data ingested\")\n",
    "\n",
    "# Healthcare Ingest\n",
    "with open(healthcare_path, 'r') as f:\n",
    "    sql = \"\"\"\n",
    "        COPY healthcare\n",
    "        FROM STDIN\n",
    "        WITH (FORMAT CSV, HEADER TRUE)\n",
    "    \"\"\"\n",
    "    cur.copy_expert(sql, f)\n",
    "\n",
    "print(\" Table 4 data ingested\")\n",
    "\n",
    "# Historics Ingest\n",
    "with open(historic_path, 'r') as f:\n",
    "    sql = \"\"\"\n",
    "        COPY historics\n",
    "        FROM STDIN\n",
    "        WITH (FORMAT CSV, HEADER TRUE)\n",
    "    \"\"\"\n",
    "    cur.copy_expert(sql, f)\n",
    "\n",
    "print(\" Table 5 data ingested\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef3072",
   "metadata": {},
   "source": [
    "### Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa4f38e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:\n",
      "(1, 'Adams', 'Unassigned', 10.71)\n",
      "(2, 'Asotin', 'Unassigned', 35.04)\n",
      "(3, 'Benton', 'Unassigned', 121.68)\n",
      "(4, 'Chelan', 'Thriving Together NCW', 27.09)\n",
      "(5, 'Clallam', 'Olympic Community of Health', 44.37)\n",
      "(6, 'Clark', 'Southwest Washington', 800.82)\n",
      "(7, 'Columbia', 'Unassigned', 4.55)\n",
      "(8, 'Cowlitz', 'Southwest Washington', 97.03)\n",
      "(9, 'Douglas', 'Thriving Together NCW', 23.6)\n",
      "(10, 'Ferry', 'Better Health Together', 3.26)\n",
      "(11, 'Franklin', 'Unassigned', 77.92)\n",
      "(12, 'Garfield', 'Unassigned', 3.22)\n",
      "(13, 'Grant', 'Thriving Together NCW', 36.99)\n",
      "(14, 'Grays Harbor', 'Cascade Pacific Action Alliance', 39.78)\n",
      "(15, 'Island', 'North Sound', 416.63)\n",
      "(16, 'Jefferson', 'Olympic Community of Health', 18.28)\n",
      "(17, 'King', 'Healthier Here', 1073.02)\n",
      "(18, 'Kitsap', 'Olympic Community of Health', 697.57)\n",
      "(19, 'Kittitas', 'Elevate Health', 20.23)\n",
      "(20, 'Klickitat', 'Southwest Washington', 12.15)\n",
      "(21, 'Lewis', 'Cascade Pacific Action Alliance', 34.19)\n",
      "(22, 'Lincoln', 'Unassigned', 4.71)\n",
      "(23, 'Mason', 'Cascade Pacific Action Alliance', 68.5)\n",
      "(24, 'Okanogan', 'Thriving Together NCW', 8.0)\n",
      "(25, 'Pacific', 'Cascade Pacific Action Alliance', 25.03)\n",
      "(26, 'Pend Oreille', 'Better Health Together', 9.57)\n",
      "(27, 'Pierce', 'Unassigned', 551.81)\n",
      "(28, 'San Juan', 'North Sound', 102.28)\n",
      "(29, 'Skagit', 'North Sound', 74.86)\n",
      "(30, 'Skamania', 'Southwest Washington', 7.0)\n",
      "(31, 'Snohomish', 'North Sound', 396.81)\n",
      "(32, 'Spokane', 'Better Health Together, Greater Health Now', 305.71)\n",
      "(33, 'Stevens', 'Better Health Together', 18.75)\n",
      "(34, 'Thurston', 'Cascade Pacific Action Alliance', 408.02)\n",
      "(35, 'Wahkiakum', 'Southwest Washington', 16.82)\n",
      "(36, 'Walla Walla', 'Unassigned', 49.28)\n",
      "(37, 'Whatcom', 'North Sound', 107.62)\n",
      "(38, 'Whitman', 'Unassigned', 22.22)\n",
      "(39, 'Yakima', 'Elevate Health', 59.78)\n"
     ]
    }
   ],
   "source": [
    "# Test Queries\n",
    "# Table 1\n",
    "cur.execute(\"SELECT * FROM county_region;\")\n",
    "rows = cur.fetchall()\n",
    "print(\"Rows:\")\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f233c216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:\n",
      "(202340, datetime.date(2023, 10, 1), datetime.date(2023, 10, 7), '2023-2024')\n",
      "(202341, datetime.date(2023, 10, 8), datetime.date(2023, 10, 14), '2023-2024')\n",
      "(202342, datetime.date(2023, 10, 15), datetime.date(2023, 10, 21), '2023-2024')\n",
      "(202343, datetime.date(2023, 10, 22), datetime.date(2023, 10, 28), '2023-2024')\n",
      "(202344, datetime.date(2023, 10, 29), datetime.date(2023, 11, 4), '2023-2024')\n",
      "(202345, datetime.date(2023, 11, 5), datetime.date(2023, 11, 11), '2023-2024')\n",
      "(202346, datetime.date(2023, 11, 12), datetime.date(2023, 11, 18), '2023-2024')\n",
      "(202347, datetime.date(2023, 11, 19), datetime.date(2023, 11, 25), '2023-2024')\n",
      "(202348, datetime.date(2023, 11, 26), datetime.date(2023, 12, 2), '2023-2024')\n",
      "(202349, datetime.date(2023, 12, 3), datetime.date(2023, 12, 9), '2023-2024')\n",
      "(202350, datetime.date(2023, 12, 10), datetime.date(2023, 12, 16), '2023-2024')\n",
      "(202351, datetime.date(2023, 12, 17), datetime.date(2023, 12, 23), '2023-2024')\n",
      "(202352, datetime.date(2023, 12, 24), datetime.date(2023, 12, 30), '2023-2024')\n",
      "(202401, datetime.date(2023, 12, 31), datetime.date(2024, 1, 6), '2023-2024')\n",
      "(202402, datetime.date(2024, 1, 7), datetime.date(2024, 1, 13), '2023-2024')\n",
      "(202403, datetime.date(2024, 1, 14), datetime.date(2024, 1, 20), '2023-2024')\n",
      "(202404, datetime.date(2024, 1, 21), datetime.date(2024, 1, 27), '2023-2024')\n",
      "(202405, datetime.date(2024, 1, 28), datetime.date(2024, 2, 3), '2023-2024')\n",
      "(202406, datetime.date(2024, 2, 4), datetime.date(2024, 2, 10), '2023-2024')\n",
      "(202407, datetime.date(2024, 2, 11), datetime.date(2024, 2, 17), '2023-2024')\n",
      "(202408, datetime.date(2024, 2, 18), datetime.date(2024, 2, 24), '2023-2024')\n",
      "(202409, datetime.date(2024, 2, 25), datetime.date(2024, 3, 2), '2023-2024')\n",
      "(202410, datetime.date(2024, 3, 3), datetime.date(2024, 3, 9), '2023-2024')\n",
      "(202411, datetime.date(2024, 3, 10), datetime.date(2024, 3, 16), '2023-2024')\n",
      "(202412, datetime.date(2024, 3, 17), datetime.date(2024, 3, 23), '2023-2024')\n",
      "(202413, datetime.date(2024, 3, 24), datetime.date(2024, 3, 30), '2023-2024')\n",
      "(202414, datetime.date(2024, 3, 31), datetime.date(2024, 4, 6), '2023-2024')\n",
      "(202415, datetime.date(2024, 4, 7), datetime.date(2024, 4, 13), '2023-2024')\n",
      "(202416, datetime.date(2024, 4, 14), datetime.date(2024, 4, 20), '2023-2024')\n",
      "(202417, datetime.date(2024, 4, 21), datetime.date(2024, 4, 27), '2023-2024')\n"
     ]
    }
   ],
   "source": [
    "# Table 2\n",
    "cur.execute(\"SELECT * FROM temporal LIMIT 30;\")\n",
    "rows = cur.fetchall()\n",
    "print(\"Rows:\")\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41c6cbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:\n",
      "(202340, 32, 'COVID-19', 'Hospitalizations', 3.8, 1.05265, 2.74735)\n",
      "(202340, 33, 'COVID-19', 'Hospitalizations', 3.8, 1.05265, 2.74735)\n",
      "(202340, 26, 'COVID-19', 'Hospitalizations', 3.8, 1.05265, 2.74735)\n",
      "(202340, 10, 'COVID-19', 'Hospitalizations', 3.8, 1.05265, 2.74735)\n",
      "(202340, 32, 'COVID-19', 'Emergency Visits', 2.7, 1.05265, 1.64735)\n",
      "(202340, 33, 'COVID-19', 'Emergency Visits', 2.7, 1.05265, 1.64735)\n",
      "(202340, 26, 'COVID-19', 'Emergency Visits', 2.7, 1.05265, 1.64735)\n",
      "(202340, 10, 'COVID-19', 'Emergency Visits', 2.7, 1.05265, 1.64735)\n",
      "(202340, 34, 'COVID-19', 'Hospitalizations', 3.8, 1.05265, 2.74735)\n",
      "(202340, 23, 'COVID-19', 'Hospitalizations', 3.8, 1.05265, 2.74735)\n",
      "(202340, 14, 'COVID-19', 'Hospitalizations', 3.8, 1.05265, 2.74735)\n",
      "(202340, 25, 'COVID-19', 'Hospitalizations', 3.8, 1.05265, 2.74735)\n",
      "(202340, 21, 'COVID-19', 'Hospitalizations', 3.8, 1.05265, 2.74735)\n",
      "(202340, 34, 'COVID-19', 'Emergency Visits', 2.5, 1.05265, 1.44735)\n",
      "(202340, 23, 'COVID-19', 'Emergency Visits', 2.5, 1.05265, 1.44735)\n",
      "(202340, 14, 'COVID-19', 'Emergency Visits', 2.5, 1.05265, 1.44735)\n",
      "(202340, 25, 'COVID-19', 'Emergency Visits', 2.5, 1.05265, 1.44735)\n",
      "(202340, 21, 'COVID-19', 'Emergency Visits', 2.5, 1.05265, 1.44735)\n",
      "(202340, 39, 'COVID-19', 'Hospitalizations', 2.3, 1.05265, 1.2473499999999997)\n",
      "(202340, 19, 'COVID-19', 'Hospitalizations', 2.3, 1.05265, 1.2473499999999997)\n",
      "(202340, 39, 'COVID-19', 'Emergency Visits', 2.4, 1.05265, 1.3473499999999998)\n",
      "(202340, 19, 'COVID-19', 'Emergency Visits', 2.4, 1.05265, 1.3473499999999998)\n",
      "(202340, 17, 'COVID-19', 'Hospitalizations', 2.4, 1.05265, 1.3473499999999998)\n",
      "(202340, 17, 'COVID-19', 'Emergency Visits', 2.3, 1.05265, 1.2473499999999997)\n",
      "(202340, 37, 'COVID-19', 'Hospitalizations', 2.9, 1.05265, 1.8473499999999998)\n",
      "(202340, 29, 'COVID-19', 'Hospitalizations', 2.9, 1.05265, 1.8473499999999998)\n",
      "(202340, 31, 'COVID-19', 'Hospitalizations', 2.9, 1.05265, 1.8473499999999998)\n",
      "(202340, 28, 'COVID-19', 'Hospitalizations', 2.9, 1.05265, 1.8473499999999998)\n",
      "(202340, 15, 'COVID-19', 'Hospitalizations', 2.9, 1.05265, 1.8473499999999998)\n",
      "(202340, 37, 'COVID-19', 'Emergency Visits', 2.8, 1.05265, 1.7473499999999997)\n"
     ]
    }
   ],
   "source": [
    "# Table 3\n",
    "cur.execute(\"SELECT * FROM illness LIMIT 30;\")\n",
    "rows = cur.fetchall()\n",
    "print(\"Rows:\")\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2a981d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:\n",
      "(1, 10.71, 0.0, 0.0, 0.0)\n",
      "(2, 35.04, 0.0, 0.0, 0.0)\n",
      "(3, 121.68, 0.0, 0.0, 0.0)\n",
      "(4, 27.09, 2.0120481927710845, 1.9375, 1.0384764865915275)\n",
      "(5, 44.37, 2.167415730337079, 1.6653333333333333, 1.3014906307068128)\n",
      "(6, 800.82, 1.9853658536585368, 1.8857142857142857, 1.0528455284552847)\n",
      "(7, 4.55, 0.0, 0.0, 0.0)\n",
      "(8, 97.03, 1.9853658536585368, 1.8857142857142857, 1.0528455284552847)\n",
      "(9, 23.6, 2.0120481927710845, 1.9375, 1.0384764865915275)\n",
      "(10, 3.26, 2.2242105263157894, 2.012987012987013, 1.1049303904923597)\n",
      "(11, 77.92, 0.0, 0.0, 0.0)\n",
      "(12, 3.22, 0.0, 0.0, 0.0)\n",
      "(13, 36.99, 2.0120481927710845, 1.9375, 1.0384764865915275)\n",
      "(14, 39.78, 2.2057471264367816, 2.010958904109589, 1.0968633530646121)\n",
      "(15, 416.63, 1.9337499999999999, 1.9126582278481012, 1.0110274652547981)\n",
      "(16, 18.28, 2.167415730337079, 1.6653333333333333, 1.3014906307068128)\n",
      "(17, 1073.02, 1.537837837837838, 1.9223684210526315, 0.7999704016131122)\n",
      "(18, 697.57, 2.167415730337079, 1.6653333333333333, 1.3014906307068128)\n",
      "(19, 20.23, 1.5466666666666666, 1.8873239436619718, 0.819502487562189)\n",
      "(20, 12.15, 1.9853658536585368, 1.8857142857142857, 1.0528455284552847)\n",
      "(21, 34.19, 2.2057471264367816, 2.010958904109589, 1.0968633530646121)\n",
      "(22, 4.71, 0.0, 0.0, 0.0)\n",
      "(23, 68.5, 2.2057471264367816, 2.010958904109589, 1.0968633530646121)\n",
      "(24, 8.0, 2.0120481927710845, 1.9375, 1.0384764865915275)\n",
      "(25, 25.03, 2.2057471264367816, 2.010958904109589, 1.0968633530646121)\n",
      "(26, 9.57, 2.2242105263157894, 2.012987012987013, 1.1049303904923597)\n",
      "(27, 551.81, 0.0, 0.0, 0.0)\n",
      "(28, 102.28, 1.9337499999999999, 1.9126582278481012, 1.0110274652547981)\n",
      "(29, 74.86, 1.9337499999999999, 1.9126582278481012, 1.0110274652547981)\n",
      "(30, 7.0, 1.9853658536585368, 1.8857142857142857, 1.0528455284552847)\n"
     ]
    }
   ],
   "source": [
    "# Table 4\n",
    "cur.execute(\"SELECT * FROM healthcare LIMIT 30;\")\n",
    "rows = cur.fetchall()\n",
    "print(\"Rows:\")\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b87e9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:\n",
      "(2020, 2020, 202001, 7.13863, 1.8131246981132074, 5.325505301886793)\n",
      "(2021, 2020, 202152, 2.68772, 1.0538401346153845, 1.6338798653846156)\n",
      "(2022, 2020, 202247, 12.9332, 2.751608, 10.181591999999998)\n",
      "(2023, 2020, 202352, 3.91859, 1.4103662692307692, 2.508223730769231)\n",
      "(2024, 2020, 202452, 6.61882, 1.588272, 5.0305480000000005)\n"
     ]
    }
   ],
   "source": [
    "# Table 5\n",
    "cur.execute(\"SELECT * FROM historics LIMIT 30;\")\n",
    "rows = cur.fetchall()\n",
    "print(\"Rows:\")\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac6ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Connection\n",
    "#conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
